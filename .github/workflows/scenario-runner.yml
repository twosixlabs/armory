---
name: üöÇ Scenario Runner

on:
  # Trigger update
  # push:

  workflow_dispatch:
    inputs:
      experiments_dir:
        type: choice
        description: 'Experiments Directory'
        required: false
        default: eval6
        options:
        - eval6
        - eval5
        - eval1-4

      debug_enabled:
        type: boolean
        description: 'Run the build with tmate debugging enabled (https://github.com/marketplace/actions/debugging-with-tmate)'
        required: false
        default: false


jobs:
  matrix_generator:
    name: Matrix Generator
    runs-on: [self-hosted]
    outputs:
      matrix: ${{ steps.generate-matrix.outputs.matrix }}
    steps:
      - name: üêÑ Got git?
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: üë©‚Äçüíª Generating Matrix
        id: generate-matrix
        run: |
          echo "::set-output name=matrix::$(find ./scenario_configs/${{ github.event.inputs.experiments_dir }} -type f -name "*.json" | jq -cnR '[inputs | select(length>0)]')"

# @christopherwoodall In getting this running on the self-hosted runner,
# I have noticed a large efficiency gain by loading the system only once
# and then running the tests without the initializations. I've pull the contents
# actions/evaluations_environment_setup into this workflow.


  matrix_job:
    runs-on: [self-hosted]
    needs: matrix_generator
    strategy:
      fail-fast: false
      matrix:
        scenario_path: ${{ fromJson(needs.matrix_generator.outputs.matrix) }}
    steps:
      - name: üêÑ Got git?
        uses: actions/checkout@v3

      - name: üêç setup python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: 3.9


      - name: ‚öôÔ∏è Installing Armory
        shell: bash
        run: |
          pip install '.[developer,pytorch]'
          armory configure --use-defaults


      - name: üöÄ Run Scenario Evaluation
        # timeout-minutes: 30
        # env:
        #   ARMORY_INSTALL: "/tmp"
        #   HOME: "/tmp"
        run: |
          # mkdir -p "/tmp/logs"

          mkdir -p "${HOME}/armory/outputs/"
          mkdir -p "${HOME}/.armory/"

          armory configure --use-defaults

          pytest \
            -c pyproject.toml \
            --verbose \
            -s ./tests/end_to_end/test_e2e_scenarios.py \
            --scenario-path ${{ matrix.scenario_path }} \
            --github-ci | tee "scenario_evaluation.log"


      - name: üìÅ Archiving Artifacts
        uses: actions/upload-artifact@v3
        # if: ${{ !failure() }}
        continue-on-error: true
        with:
          name: evaluation-artifacts
          retention-days: 1
          path: |
            /tmp/.armory/outputs/
